import streamlit as st
import requests
import json
import base64
import time
from io import BytesIO
from gtts import gTTS

# --- CONFIGURATION ---
st.set_page_config(page_title="Vista Vocale", layout="wide")

try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    st.error("‚ùå API Key missing. Please check Secrets.")
    st.stop()

# --- STYLING ---
st.markdown("""
    <style>
    button[data-baseweb="tab"] { font-size: 16px !important; padding: 8px 12px !important; flex: 1 1 auto; }
    h1 { font-size: 2.2rem !important; }
    div[data-baseweb="select"] { text-align: center; }
    .pinyin { color: #888; font-size: 0.9rem; font-style: italic; margin-bottom: 5px; }
    </style>
""", unsafe_allow_html=True)

# --- LANGUAGE SETTINGS ---
LANG_CONFIG = {
    "üáÆüáπ Italian": { "code": "it", "name": "Italian", "super7": "essere, avere, volere, andare, piacere, c'√®, potere" },
    "üá´üá∑ French": { "code": "fr", "name": "French", "super7": "√™tre, avoir, vouloir, aller, aimer, il y a, pouvoir" },
    "üá®üá≥ Chinese": { "code": "zh-CN", "name": "Mandarin Chinese", "super7": "ÊòØ (sh√¨), Êúâ (y«íu), Ë¶Å (y√†o), Âéª (q√π), ÂñúÊ¨¢ (x«êhuƒÅn), Âú® (z√†i), ËÉΩ (n√©ng)" }
}

# --- 1. INTELLIGENT MODEL MANAGER ---
@st.cache_data
def get_prioritized_models():
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={API_KEY}"
    try:
        response = requests.get(url)
        if response.status_code != 200: return []
        data = response.json()
        
        valid_models = []
        for m in data.get('models', []):
            name = m['name']
            methods = m.get('supportedGenerationMethods', [])
            if "generateContent" not in methods: continue
            if "tts" in name.lower(): continue
            if "embedding" in name.lower(): continue
            valid_models.append(name)
        
        def sort_key(name):
            if "gemini-2.5-flash-lite" in name: return 0
            if "gemini-2.5-flash" in name: return 1
            if "gemini-3" in name: return 2
            if "gemini-2.5" in name: return 3
            return 99 
        valid_models.sort(key=sort_key)
        return valid_models
    except:
        return []

# --- 2. THE AUTO-PILOT ENGINE ---
def generate_lesson_with_fallback(image_bytes, lang_config, models_list):
    for attempt, model_name in enumerate(models_list[:4]): 
        status_placeholder = st.empty()
        status_placeholder.info(f"Attempt {attempt+1}: Connecting to `{model_name}`...")
        
        url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={API_KEY}"
        b64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        prompt_text = f"""
        You are an expert TPRS {lang_config['name']} teacher.
        Analyze the image and create a lesson strictly following these rules:
        1. Select 5 High-Frequency Vocabulary words visible in the image.
        2. Create a simple Conversation that uses ONLY these words and "Super 7" verbs: {lang_config['super7']}.
        3. Create a Story (5-6 sentences) that RECYCLES the vocab words.
        4. Keep level A1 (Beginner).
        CRITICAL: If CHINESE use Pinyin. If ITALIAN/FRENCH leave pronunciation empty.
        Return JSON.
        """
        
        payload = {
            "contents": [{"parts": [{"text": prompt_text}, {"inline_data": {"mime_type": "image/jpeg", "data": b64_image}}]}],
            "generation_config": {"response_mime_type": "application/json"}
        }
        
        try:
            response = requests.post(url, json=payload, headers={'Content-Type': 'application/json'})
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and result['candidates']:
                    text_content = result['candidates'][0]['content']['parts'][0]['text']
                    status_placeholder.success(f"‚úÖ Success! Generated by `{model_name}`")
                    time.sleep(1)
                    status_placeholder.empty()
                    try:
                        parsed_json = json.loads(text_content.replace('```json', '').replace('```', ''))
                        return parsed_json, None, model_name
                    except:
                        return None, "AI returned text but it wasn't valid JSON.", model_name

            if response.status_code in [429, 400, 503]:
                status_placeholder.warning(f"‚ö†Ô∏è `{model_name}` failed. Switching engines...")
                time.sleep(1)
                continue
            
            return None, f"Error ({response.status_code}): {response.text}", model_name
            
        except Exception as e:
            return None, str(e), model_name
            
    return None, "All available models failed.", "All"

# --- 3. HELPER: FLEXIBLE DATA READER ---
# This looks for keys even if the AI misnames them (e.g. "Word" instead of "target_word")
def get_any(d, keys, default=""):
    for k in keys:
        if k in d and d[k]:
            return d[k]
        # Also try lowercase version
        if k.lower() in d and d[k.lower()]:
             return d[k.lower()]
    return default

# --- 4. GALLERY DOWNLOADER ---
@st.cache_data(show_spinner=False)
def load_gallery_image(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        return response.content
    except Exception as e: return None

# --- 5. HELPER: TEXT FILE ---
def create_lesson_file(data, lang_name):
    text = f"üåç VISTA VOCALE - {lang_name.upper()} LESSON\n==========================================\n\n"
    # Note: We aren't using the flexible reader here for simplicity, but the download usually matches
    text += "(Detailed content available in app tabs)"
    return str(data) # Quick dump for safety

def get_audio_bytes(text, lang_code):
    try:
        fp = BytesIO()
        gTTS(text=text, lang=lang_code).write_to_fp(fp)
        fp.seek(0)
        return fp
    except: return None

# --- MAIN APP LAYOUT ---
st.title("üåç Vista Vocale")
my_models = get_prioritized_models()

t_upload, t_gallery = st.tabs(["üì∑ Snap Photo", "üñºÔ∏è Gallery"])
final_image_bytes = None

with t_upload:
    uploaded_file = st.file_uploader("Take a photo:", type=["jpg", "png", "jpeg", "webp"])
    if uploaded_file: final_image_bytes = uploaded_file.getvalue()

with t_gallery:
    GALLERY = {
        "Select...": None,
        "‚òï Espresso": "https://upload.wikimedia.org/wikipedia/commons/4/45/A_small_cup_of_coffee.JPG",
        "üõ∂ Venice": "https://upload.wikimedia.org/wikipedia/commons/d/d6/Gondola_Venice_2016.jpg",
        "ü•ê Croissant (French)": "https://upload.wikimedia.org/wikipedia/commons/2/28/2018_01_Croissant_IMG_0685.JPG",
        "ü•ü Dumplings (Chinese)": "https://upload.wikimedia.org/wikipedia/commons/9/93/Jiaozi_at_Wangfujing.JPG"
    }
    choice = st.selectbox("Choose scene:", list(GALLERY.keys()))
    if choice and GALLERY[choice]:
        loaded_bytes = load_gallery_image(GALLERY[choice])
        if loaded_bytes: final_image_bytes = loaded_bytes

st.markdown("---")

if final_image_bytes:
    c1, c2, c3 = st.columns([1, 2, 1]) 
    with c2:
        st.image(final_image_bytes, use_container_width=True)
        selected_lang_key = st.selectbox("Select Target Language:", list(LANG_CONFIG.keys()), index=0)
        current_lang = LANG_CONFIG[selected_lang_key]
        
        if st.button(f"Create {current_lang['name']} Lesson", type="primary", use_container_width=True):
            if not my_models:
                 st.error("Could not find any AI models in your account.")
            else:
                lesson_data, error, used_model = generate_lesson_with_fallback(final_image_bytes, current_lang, my_models)
                
                if error:
                    st.error(error)
                elif lesson_data:
                    st.session_state['lesson_data'] = lesson_data
                    st.session_state['current_lang'] = current_lang
                    st.session_state['used_model'] = used_model

    if 'lesson_data' in st.session_state:
        data = st.session_state['lesson_data']
        lang = st.session_state['current_lang']
        st.caption(f"‚ú® Generated using: `{st.session_state.get('used_model', 'Unknown')}`")
        st.markdown("---")
        t1, t2, t3, t4, t5, t6 = st.tabs(["üìñ Vocab", "üó£Ô∏è Chat", "üìú Story", "üá∫üá∏ Key", "üíæ Save", "üîç Debug"])
        
        # --- TAB 1: VOCAB ---
        with t1:
            for item in data.get('vocabulary', []):
                if isinstance(item, dict):
                    c1, c2 = st.columns([3, 1])
                    with c1:
                        # Try finding the word using multiple possible key names
                        word = get_any(item, ['target_word', 'word', 'term', 'vocabulary'])
                        pron = get_any(item, ['pronunciation', 'pinyin', 'pron'])
                        sent = get_any(item, ['target_sentence', 'sentence', 'example'])
                        
                        st.markdown(f"**{word}**")
                        if pron: st.markdown(f"<div class='pinyin'>{pron}</div>", unsafe_allow_html=True)
                        st.markdown(f"_{sent}_")
                    with c2:
                        ab = get_audio_bytes(f"{word}... {sent}", lang['code'])
                        if ab: st.audio(ab, format='audio/mp3')
                    st.divider()
                else:
                    st.markdown(f"‚Ä¢ {str(item)}")

        # --- TAB 2: CHAT ---
        with t2:
            for turn in data.get('conversation', []):
                c1, c2 = st.columns([3, 1])
                with c1:
                    if isinstance(turn, dict):
                        speaker = get_any(turn, ['speaker', 'person', 'role'], 'Speaker')
                        text = get_any(turn, ['target_text', 'text', 'message', 'sentence'])
                        pron = get_any(turn, ['pronunciation', 'pinyin'])
                        
                        st.markdown(f"**{speaker}**: {text}")
                        if pron: st.markdown(f"<div class='pinyin'>{pron}</div>", unsafe_allow_html=True)
                        text_for_audio = text
                    else:
                        st.markdown(str(turn))
                        text_for_audio = str(turn)
                with c2:
                    ab = get_audio_bytes(text_for_audio, lang['code'])
                    if ab: st.audio(ab, format='audio/mp3')
                st.divider()

        # --- TAB 3: STORY ---
        with t3:
            for chunk in data.get('story', []):
                c1, c2 = st.columns([3, 1])
                with c1:
                    if isinstance(chunk, dict):
                        text = get_any(chunk, ['target_text', 'text', 'sentence', 'story'])
                        pron = get_any(chunk, ['pronunciation', 'pinyin'])
                        
                        st.markdown(f"üìñ {text}")
                        if pron: st.markdown(f"<div class='pinyin'>{pron}</div>", unsafe_allow_html=True)
                        text_for_audio = text
                    else:
                        st.markdown(f"üìñ {str(chunk)}")
                        text_for_audio = str(chunk)
                with c2:
                    ab = get_audio_bytes(text_for_audio, lang['code'])
                    if ab: st.audio(ab, format='audio/mp3')
                st.divider()

        # --- TAB 4: ANSWER KEY ---
        with t4:
            st.header("üá∫üá∏ Answer Key")
            for item in data.get('vocabulary', []):
                if isinstance(item, dict):
                    word = get_any(item, ['target_word', 'word'])
                    obj = get_any(item, ['object_name', 'english_word', 'meaning'])
                    trans = get_any(item, ['english_translation', 'translation', 'english'])
                    
                    st.markdown(f"**{word}** = *{obj}*")
                    st.caption(f"Sent: {trans}")
                    st.divider()

        # --- TAB 5: DOWNLOAD ---
        with t5:
            st.header("üíæ Download")
            # Quick dump
            st.json(data)

        # --- TAB 6: DEBUG DATA ---
        with t6:
            st.info("If the tabs are empty, look at this raw data to see what keys the AI used!")
            st.json(data)
