import streamlit as st
import requests
import json
import base64
from io import BytesIO
from gtts import gTTS
from PIL import Image

# --- CONFIGURATION ---
st.set_page_config(page_title="Vista Vocale", layout="wide")

try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    st.error("‚ùå API Key missing. Please check Secrets.")
    st.stop()

# --- STYLING ---
st.markdown("""
    <style>
    button[data-baseweb="tab"] { font-size: 18px !important; padding: 10px !important; }
    h1 { font-size: 2.2rem !important; }
    p, li { font-size: 1.1rem !important; }
    [data-testid="stDownloadButton"] > button { width: 100%; }
    </style>
""", unsafe_allow_html=True)

# --- LANGUAGE SETTINGS ---
LANG_CONFIG = {
    "üáÆüáπ Italian": {
        "code": "it",
        "name": "Italian",
        "super7": "essere, avere, volere, andare, piacere, c'√®, potere"
    },
    "üá´üá∑ French": {
        "code": "fr",
        "name": "French",
        "super7": "√™tre, avoir, vouloir, aller, aimer, il y a, pouvoir"
    },
    "üá®üá≥ Chinese": {
        "code": "zh-CN",
        "name": "Mandarin Chinese",
        "super7": "ÊòØ (sh√¨), Êúâ (y«íu), Ë¶Å (y√†o), Âéª (q√π), ÂñúÊ¨¢ (x«êhuƒÅn), Âú® (z√†i), ËÉΩ (n√©ng)"
    }
}

# --- SIDEBAR SELECTOR ---
with st.sidebar:
    st.header("üåç Language Settings")
    selected_lang_key = st.radio("Target Language:", list(LANG_CONFIG.keys()))
    current_lang = LANG_CONFIG[selected_lang_key]

# --- 1. AUTO-DISCOVERY ---
@st.cache_data
def get_best_model_name():
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={API_KEY}"
    try:
        response = requests.get(url)
        if response.status_code != 200:
            return None, f"List Error: {response.status_code}"
        
        data = response.json()
        models = data.get('models', [])
        
        priority_list = [
            "gemini-1.5-flash",
            "gemini-1.5-flash-latest",
            "gemini-1.5-flash-001",
            "gemini-1.5-pro"
        ]
        
        for priority in priority_list:
            for m in models:
                if priority in m['name']:
                    return m['name'], None

        for m in models:
            if "generateContent" in m.get('supportedGenerationMethods', []):
                return m['name'], None
                
        return "models/gemini-1.5-flash", None
        
    except Exception as e:
        return None, str(e)

valid_model_name, model_error = get_best_model_name()

# --- 2. GALLERY DOWNLOADER ---
@st.cache_data(show_spinner=False)
def load_gallery_image(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        return response.content
    except Exception as e:
        return None

# --- 3. HELPER: TEXT FILE ---
def create_lesson_file(data, lang_name):
    text = f"üåç VISTA VOCALE - {lang_name.upper()} LESSON\n"
    text += "==========================================\n\n"
    
    text += "1. VOCABULARY\n"
    text += "-------------\n"
    for item in data.get('vocabulary', []):
        if isinstance(item, dict):
            text += f"* {item.get('target_word')} ({item.get('object_name')})\n"
            text += f"  - {item.get('target_sentence')}\n"
            text += f"  - {item.get('english_translation')}\n\n"

    text += "2. CONVERSATION\n"
    text += "---------------\n"
    for turn in data.get('conversation', []):
        if isinstance(turn, dict):
            text += f"{turn.get('speaker')}: {turn.get('target_text')}\n"
            text += f"   ({turn.get('english')})\n"
    text += "\n"

    text += "3. STORY\n"
    text += "--------\n"
    for chunk in data.get('story', []):
        if isinstance(chunk, dict):
            text += f"{chunk.get('target_text')}\n"
            text += f"({chunk.get('english')})\n\n"
    
    text += "\n\n(Generated by Vista Vocale)"
    return text

# --- 4. DIRECT API CALL (DYNAMIC LANGUAGE) ---
def call_gemini_direct(image_bytes, model_name, lang_config):
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={API_KEY}"
    b64_image = base64.b64encode(image_bytes).decode('utf-8')
    
    # We inject the selected language and verbs into the prompt
    prompt_text = f"""
    You are an expert TPRS {lang_config['name']} teacher.
    Analyze the image and create a lesson that STRICTLY follows these rules:
    
    1. Select 5 High-Frequency Vocabulary words visible in the image (in {lang_config['name']}).
    2. Create a simple Conversation that uses ONLY these 5 words and "Super 7" verbs: {lang_config['super7']}.
    3. Create a Story (5-6 sentences) that RECYCLES the 5 vocabulary words.
    4. Keep the level strictly A1 (Beginner). 
    
    Return JSON strictly following this structure (use keys exactly as shown):
    {{
      "vocabulary": [{{"target_word": "word in target language", "target_sentence": "sentence in target language", "english_translation": "english", "object_name": "english name of object"}}],
      "conversation": [{{"speaker": "Name", "target_text": "text in target language", "english": "english translation"}}],
      "story": [{{"target_text": "sentence in target language", "english": "english translation"}}]
    }}
    """
    
    payload = {
        "contents": [{
            "parts": [
                {"text": prompt_text},
                {"inline_data": {"mime_type": "image/jpeg", "data": b64_image}}
            ]
        }],
        "generation_config": {"response_mime_type": "application/json"}
    }
    
    try:
        response = requests.post(url, json=payload, headers={'Content-Type': 'application/json'})
        if response.status_code != 200:
            return None, f"API Error ({response.status_code}): {response.text}"
            
        result = response.json()
        if 'candidates' in result and result['candidates']:
             text_content = result['candidates'][0]['content']['parts'][0]['text']
             text_content = text_content.replace('```json', '').replace('```', '')
             return json.loads(text_content), None
        else:
             return None, "AI returned no content."
        
    except Exception as e:
        return None, str(e)

def get_audio_bytes(text, lang_code):
    try:
        # Generate audio using the specific language code (it, fr, zh-CN)
        tts = gTTS(text=text, lang=lang_code)
        fp = BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        return fp
    except: return None

# --- MAIN APP LAYOUT ---
st.title(f"{selected_lang_key.split()[0]} Vista Vocale") 

if model_error:
    st.error(f"‚ö†Ô∏è Could not find models: {model_error}")
else:
    st.caption(f"‚ú® Connected to: `{valid_model_name}` | Learning: {current_lang['name']}")

t_upload, t_gallery = st.tabs(["üì∑ Snap Photo", "üñºÔ∏è Gallery"])
final_image_bytes = None

with t_upload:
    uploaded_file = st.file_uploader("Take a photo:", type=["jpg", "png", "jpeg", "webp"])
    if uploaded_file:
        final_image_bytes = uploaded_file.getvalue()

with t_gallery:
    GALLERY = {
        "Select...": None,
        "‚òï Espresso": "https://upload.wikimedia.org/wikipedia/commons/4/45/A_small_cup_of_coffee.JPG",
        "üõ∂ Venice": "https://upload.wikimedia.org/wikipedia/commons/d/d6/Gondola_Venice_2016.jpg",
        "ü•ê Croissant (French)": "https://upload.wikimedia.org/wikipedia/commons/2/28/2018_01_Croissant_IMG_0685.JPG",
        "ü•ü Dumplings (Chinese)": "https://upload.wikimedia.org/wikipedia/commons/9/93/Jiaozi_at_Wangfujing.JPG"
    }
    choice = st.selectbox("Choose scene:", list(GALLERY.keys()))
    if choice and GALLERY[choice]:
        loaded_bytes = load_gallery_image(GALLERY[choice])
        if loaded_bytes:
            final_image_bytes = loaded_bytes
        else:
            st.error("‚ö†Ô∏è Could not download image.")

st.markdown("---")

if final_image_bytes:
    c1, c2, c3 = st.columns([1, 2, 1]) 
    with c2:
        st.image(final_image_bytes, use_container_width=True)
    
    if st.button(f"Create {current_lang['name']} Lesson", type="primary"):
        with st.spinner("Analyzing..."):
            # Pass the Language Config to the AI
            lesson_data, error = call_gemini_direct(final_image_bytes, valid_model_name, current_lang)
            
            if error:
                st.error(error)
            elif lesson_data:
                t1, t2, t3, t4, t5 = st.tabs(["üìñ VOCAB", "üó£Ô∏è CHAT", "üìú STORY", "üá∫üá∏ TRANSLATION", "üñ®Ô∏è SAVE"])
                
                # --- TAB 1: VOCAB ---
                with t1:
                    vocab_list = lesson_data.get('vocabulary', [])
                    if isinstance(vocab_list, list):
                        for item in vocab_list:
                            if isinstance(item, dict):
                                c1, c2 = st.columns([3, 1])
                                with c1:
                                    st.markdown(f"**{item.get('target_word', '')}**")
                                    st.markdown(f"_{item.get('target_sentence', '')}_")
                                with c2:
                                    ab = get_audio_bytes(f"{item.get('target_word', '')}... {item.get('target_sentence', '')}", current_lang['code'])
                                    if ab: st.audio(ab, format='audio/mp3')
                                st.divider()
                            
                # --- TAB 2: CHAT ---
                with t2:
                    chat_list = lesson_data.get('conversation', [])
                    if isinstance(chat_list, list):
                        for turn in chat_list:
                            c1, c2 = st.columns([3, 1])
                            with c1:
                                if isinstance(turn, dict):
                                    speaker = turn.get('speaker', 'Speaker')
                                    text = turn.get('target_text', '')
                                    st.markdown(f"**{speaker}**: {text}")
                                else:
                                    st.markdown(str(turn))
                                    text = str(turn)
                            with c2:
                                ab = get_audio_bytes(text, current_lang['code'])
                                if ab: st.audio(ab, format='audio/mp3')
                            st.divider()

                # --- TAB 3: STORY ---
                with t3:
                    story_list = lesson_data.get('story', [])
                    if isinstance(story_list, list):
                        for chunk in story_list:
                            c1, c2 = st.columns([3, 1])
                            with c1:
                                if isinstance(chunk, dict):
                                    text = chunk.get('target_text', '')
                                    st.markdown(f"üìñ {text}")
                                else:
                                    text = str(chunk)
                                    st.markdown(f"üìñ {text}")
                            with c2:
                                ab = get_audio_bytes(text, current_lang['code'])
                                if ab: st.audio(ab, format='audio/mp3')
                            st.divider()

                # --- TAB 4: TRANSLATIONS ---
                with t4:
                    st.header("üá∫üá∏ English Translations")
                    st.subheader("1. Vocabulary")
                    if isinstance(vocab_list, list):
                        for item in vocab_list:
                             if isinstance(item, dict):
                                 st.markdown(f"**{item.get('target_word')}** = *{item.get('object_name')}*")
                                 st.caption(f"Sent: {item.get('english_translation')}")
                                 st.divider()

                    st.subheader("2. Conversation")
                    if isinstance(chat_list, list):
                        for turn in chat_list:
                             if isinstance(turn, dict):
                                 st.markdown(f"**{turn.get('speaker')}**: {turn.get('english')}")

                    st.markdown("---")
                    st.subheader("3. Story")
                    if isinstance(story_list, list):
                        for chunk in story_list:
                             if isinstance(chunk, dict):
                                 st.markdown(f"_{chunk.get('english')}_")
                                 st.markdown("")

                # --- TAB 5: PRINT / SAVE ---
                with t5:
                    st.header("üñ®Ô∏è Save Lesson Plan")
                    lesson_text = create_lesson_file(lesson_data, current_lang['name'])
                    
                    st.download_button(
                        label=f"üì• Download {current_lang['name']} Lesson",
                        data=lesson_text,
                        file_name=f"{current_lang['name']}_Lesson.txt",
                        mime="text/plain"
                    )
                    st.markdown("---")
                    st.text(lesson_text)
